<html><head><META http-equiv="Content-Type" content="text/html; charset=utf-8"><title>CouchDB Release 1.1 Feature Guide</title><link href="..//DocKit/xsl.d/html-css/html.css" type="text/css" rel="stylesheet"><meta content="DocBook XSL Stylesheets V1.76.1" name="generator"><meta name="description" content="This document provides details on the new features introduced in the CouchDB 1.1 release from the CouchDB 1.0.x release series. Last document update: 25 Jan 2012 14:44; Document built: 21 Feb 2012 20:8."></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="article" title="CouchDB Release 1.1 Feature Guide"><div class="titlepage"><div><div><h2 class="title"><a name="couchdb-release-1.1"></a>CouchDB Release 1.1 Feature Guide</h2></div><div><div class="abstract" title="Abstract"><p class="title"><b>Abstract</b></p><p>
        This document provides details on the new features introduced in
        the CouchDB 1.1 release from the CouchDB 1.0.x release series.
      </p><p>
  <span class="emphasis"><em>Last document update</em></span>: 25 Jan 2012 14:44;
  <span class="emphasis"><em>Document built</em></span>: 21 Feb 2012 20:8.
</p></div></div></div><hr></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#couchdb-release-1.1-upgrading">1. Upgrading to CouchDB 1.1</a></span></dt><dt><span class="section"><a href="#couchb-release-1.1-replicatordb">2. Replicator Database</a></span></dt><dd><dl><dt><span class="section"><a href="#couchdb-release-1.1-replicatordb-basics">2.1. Basics</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-replicatordb-docsame">2.2. Documents describing the same replication</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-replicatordb-cancel">2.3. Canceling replications</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-replicatordb-restart">2.4. Server restart</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-replicatordb-changing">2.5. Changing the Replicator Database</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-replicatordb-replicating">2.6. Replicating the replicator database</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-replicatordb-delegations">2.7. Delegations</a></span></dt></dl></dd><dt><span class="section"><a href="#couchdb-release-1.1-ssl">3. Native SSL Support</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-httprange">4. HTTP Range Requests</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-proxying">5. HTTP Proxying</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-commonjs">6. Added CommonJS support to map functions</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-etag">7. More granular ETag support for views</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-filters">8. Added built-in filters for <code class="literal">_changes</code>:
      <code class="literal">_doc_ids</code> and <code class="literal">_design</code>.</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-wildcards">9. Allow wildcards in vhosts definitions</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-osprocess">10. OS Daemons</a></span></dt><dt><span class="section"><a href="#coudhdb-release-1.1-updateafter">11. Stale views and <code class="literal">update_after</code></a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-socketoptions">12. Socket Options Configuration Setting</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-serveroptions">13. Server Options Configuration Setting</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-errormessages">14. Improved Error Messages</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-microoptimizations">15. Multiple micro-optimizations when reading data.</a></span></dt></dl></div><div class="section" title="1.&nbsp;Upgrading to CouchDB 1.1"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="couchdb-release-1.1-upgrading"></a>1.&nbsp;Upgrading to CouchDB 1.1</h2></div></div></div><p>
      You can upgrade your existing CouchDB 1.0.x installation to
      CouchDB 1.1 without any specific steps or migration. When you run
      CouchDB 1.1 the existing data and index files will be opened and
      used as normal.
    </p><p>
      The first time you run a compaction routine on your database
      within CouchDB 1.1, the data structure and indexes will be updated
      to the new version of the CouchDB database format that can only be
      read by CouchDB 1.1 and later. This step is not reversable. Once
      the data files have been updated and migrated to the new version
      the data files will no longer work with a CouchDB 1.0.x release.
    </p><div class="warning" title="Warning" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Warning</h3><p>
        If you want to retain support for openein gthe data files in
        CouchDB 1.0.x you must back up your data files before performing
        the upgrade and compaction process.
      </p></div></div><div class="section" title="2.&nbsp;Replicator Database"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="couchb-release-1.1-replicatordb"></a>2.&nbsp;Replicator Database</h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#couchdb-release-1.1-replicatordb-basics">2.1. Basics</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-replicatordb-docsame">2.2. Documents describing the same replication</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-replicatordb-cancel">2.3. Canceling replications</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-replicatordb-restart">2.4. Server restart</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-replicatordb-changing">2.5. Changing the Replicator Database</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-replicatordb-replicating">2.6. Replicating the replicator database</a></span></dt><dt><span class="section"><a href="#couchdb-release-1.1-replicatordb-delegations">2.7. Delegations</a></span></dt></dl></div><p>
      A database where you
      <code class="literal">PUT</code>/<code class="literal">POST</code> documents to
      trigger replications and you <code class="literal">DELETE</code> to cancel
      ongoing replications. These documents have exactly the same
      content as the JSON objects we used to <code class="literal">POST</code> to
      <code class="literal">_replicate</code> (fields <code class="literal">source</code>,
      <code class="literal">target</code>, <code class="literal">create_target</code>,
      <code class="literal">continuous</code>, <code class="literal">doc_ids</code>,
      <code class="literal">filter</code>, <code class="literal">query_params</code>.
    </p><p>
      Replication documents can have a user defined
      <code class="literal">_id</code>. Design documents (and
      <code class="literal">_local</code> documents) added to the replicator
      database are ignored.
    </p><p>
      The default name of this database is
      <code class="literal">_replicator</code>. The name can be changed in the
      <code class="filename">local.ini</code> configuration, section
      <code class="literal">[replicator]</code>, parameter <code class="literal">db</code>.
    </p><div class="section" title="2.1.&nbsp;Basics"><div class="titlepage"><div><div><h3 class="title"><a name="couchdb-release-1.1-replicatordb-basics"></a>2.1.&nbsp;Basics</h3></div></div></div><p>
        Let's say you PUT the following document into _replicator:
      </p><pre class="programlisting">{
    "_id": "my_rep",
    "source":  "http://myserver.com:5984/foo",
    "target":  "bar",
    "create_target":  true
}</pre><p>
        In the couch log you'll see 2 entries like these:
      </p><pre class="programlisting">[Thu, 17 Feb 2011 19:43:59 GMT] [info] [&lt;0.291.0&gt;] Document `my_rep` triggered replication `c0ebe9256695ff083347cbf95f93e280+create_target`
[Thu, 17 Feb 2011 19:44:37 GMT] [info] [&lt;0.124.0&gt;] Replication `c0ebe9256695ff083347cbf95f93e280+create_target` finished (triggered by document `my_rep`)</pre><p>
        As soon as the replication is triggered, the document will be
        updated by CouchDB with 3 new fields:
      </p><pre class="programlisting">{
    "_id": "my_rep",
    "source":  "http://myserver.com:5984/foo",
    "target":  "bar",
    "create_target":  true,
    "_replication_id":  "c0ebe9256695ff083347cbf95f93e280",
    "_replication_state":  "triggered",
    "_replication_state_time":  1297974122
}</pre><p>
        Special fields set by the replicator start with the prefix
        <code class="literal">_replication_</code>.
      </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>
            <code class="literal">_replication_id</code>
          </p><p>
            The ID internally assigned to the replication. This is also
            the ID exposed by <code class="literal">/_active_tasks</code>.
          </p></li><li class="listitem"><p>
            <code class="literal">_replication_state</code>
          </p><p>
            The current state of the replication.
          </p></li><li class="listitem"><p>
            <code class="literal">_replication_state_time</code>
          </p><p>
            A Unix timestamp (number of seconds since 1 Jan 1970) that
            tells us when the current replication state (marked in
            <code class="literal">_replication_state</code>) was set.
          </p></li></ul></div><p>
        When the replication finishes, it will update the
        <code class="literal">_replication_state</code> field (and
        <code class="literal">_replication_state_time</code>) with the value
        <code class="literal">completed</code>, so the document will look like:
      </p><pre class="programlisting">{
    "_id": "my_rep",
    "source":  "http://myserver.com:5984/foo",
    "target":  "bar",
    "create_target":  true,
    "_replication_id":  "c0ebe9256695ff083347cbf95f93e280",
    "_replication_state":  "completed",
    "_replication_state_time":  1297974122
}</pre><p>
        When an error happens during replication, the
        <code class="literal">_replication_state</code> field is set to
        <code class="literal">error</code> (and
        <code class="literal">_replication_state</code> gets updated of course).
      </p><p>
        When you PUT/POST a document to the
        <code class="literal">_replicator</code> database, CouchDB will attempt to
        start the replication up to 10 times (configurable under
        <code class="literal">[replicator]</code>, parameter
        <code class="literal">max_replication_retry_count</code>). If it fails on
        the first attempt, it waits 5 seconds before doing a second
        attempt. If the second attempt fails, it waits 10 seconds before
        doing a third attempt. If the third attempt fails, it waits 20
        seconds before doing a fourth attempt (each attempt doubles the
        previous wait period). When an attempt fails, the Couch log will
        show you something like:
      </p><pre class="programlisting">[error] [&lt;0.149.0&gt;] Error starting replication `67c1bb92010e7abe35d7d629635f18b6+create_target` (document `my_rep_2`): {db_not_found,&lt;&lt;"could not open http://myserver:5986/foo/"&gt;&gt;</pre><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
          The <code class="literal">_replication_state</code> field is only set to
          <code class="literal">error</code> when all the attempts were
          unsuccessful.
        </p></div><p>
        There are only 3 possible values for the
        <code class="literal">_replication_state</code> field:
        <code class="literal">triggered</code>, <code class="literal">completed</code> and
        <code class="literal">error</code>. Continuous replications never get
        their state set to <code class="literal">completed</code>.
      </p></div><div class="section" title="2.2.&nbsp;Documents describing the same replication"><div class="titlepage"><div><div><h3 class="title"><a name="couchdb-release-1.1-replicatordb-docsame"></a>2.2.&nbsp;Documents describing the same replication</h3></div></div></div><p>
        Lets suppose 2 documents are added to the
        <code class="literal">_replicator</code> database in the following order:
      </p><pre class="programlisting">{
    "_id": "doc_A",
    "source":  "http://myserver.com:5984/foo",
    "target":  "bar"
}</pre><p>
        and
      </p><pre class="programlisting">{
    "_id": "doc_B",
    "source":  "http://myserver.com:5984/foo",
    "target":  "bar"
}</pre><p>
        Both describe exactly the same replication (only their
        <code class="literal">_ids</code> differ). In this case document
        <code class="literal">doc_A</code> triggers the replication, getting
        updated by CouchDB with the fields
        <code class="literal">_replication_state</code>,
        <code class="literal">_replication_state_time</code> and
        <code class="literal">_replication_id</code>, just like it was described
        before. Document <code class="literal">doc_B</code> however, is only
        updated with one field, the <code class="literal">_replication_id</code>
        so it will look like this:
      </p><pre class="programlisting">{
    "_id": "doc_B",
    "source":  "http://myserver.com:5984/foo",
    "target":  "bar",
    "_replication_id":  "c0ebe9256695ff083347cbf95f93e280"
}</pre><p>
        While document <code class="literal">doc_A</code> will look like this:
      </p><pre class="programlisting">{
    "_id": "doc_A",
    "source":  "http://myserver.com:5984/foo",
    "target":  "bar",
    "_replication_id":  "c0ebe9256695ff083347cbf95f93e280",
    "_replication_state":  "triggered",
    "_replication_state_time":  1297974122
}</pre><p>
        Note that both document get exactly the same value for the
        <code class="literal">_replication_id</code> field. This way you can
        identify which documents refer to the same replication - you can
        for example define a view which maps replication IDs to document
        IDs.
      </p></div><div class="section" title="2.3.&nbsp;Canceling replications"><div class="titlepage"><div><div><h3 class="title"><a name="couchdb-release-1.1-replicatordb-cancel"></a>2.3.&nbsp;Canceling replications</h3></div></div></div><p>
        To cancel a replication simply <code class="literal">DELETE</code> the
        document which triggered the replication. The Couch log will
        show you an entry like the following:
      </p><pre class="programlisting">[Thu, 17 Feb 2011 20:16:29 GMT] [info] [&lt;0.125.0&gt;] Stopped replication `c0ebe9256695ff083347cbf95f93e280+continuous+create_target` because replication document `doc_A` was deleted</pre><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
          You need to <code class="literal">DELETE</code> the document that
          triggered the replication. <code class="literal">DELETE</code>ing
          another document that describes the same replication but did
          not trigger it, will not cancel the replication.
        </p></div></div><div class="section" title="2.4.&nbsp;Server restart"><div class="titlepage"><div><div><h3 class="title"><a name="couchdb-release-1.1-replicatordb-restart"></a>2.4.&nbsp;Server restart</h3></div></div></div><p>
        When CouchDB is restarted, it checks its
        <code class="literal">_replicator</code> database and restarts any
        replication that is described by a document that either has its
        <code class="literal">_replication_state</code> field set to
        <code class="literal">triggered</code> or it doesn't have yet the
        <code class="literal">_replication_state</code> field set.
      </p><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
          Continuous replications always have a
          <code class="literal">_replication_state</code> field with the value
          <code class="literal">triggered</code>, therefore they're always
          restarted when CouchDB is restarted.
        </p></div></div><div class="section" title="2.5.&nbsp;Changing the Replicator Database"><div class="titlepage"><div><div><h3 class="title"><a name="couchdb-release-1.1-replicatordb-changing"></a>2.5.&nbsp;Changing the Replicator Database</h3></div></div></div><p>
        Imagine your replicator database (default name is _replicator)
        has the two following documents that represent pull replications
        from servers A and B:
      </p><pre class="programlisting">{
    "_id": "rep_from_A",
    "source":  "http://aserver.com:5984/foo",
    "target":  "foo_a",
    "continuous":  true,
    "_replication_id":  "c0ebe9256695ff083347cbf95f93e280",
    "_replication_state":  "triggered",
    "_replication_state_time":  1297971311
}
{
    "_id": "rep_from_B",
    "source":  "http://bserver.com:5984/foo",
    "target":  "foo_b",
    "continuous":  true,
    "_replication_id":  "231bb3cf9d48314eaa8d48a9170570d1",
    "_replication_state":  "triggered",
    "_replication_state_time":  1297974122
}</pre><p>
        Now without stopping and restarting CouchDB, you change the name
        of the replicator database to
        <code class="literal">another_replicator_db</code>:
      </p><pre class="programlisting">$ curl -X PUT http://localhost:5984/_config/replicator/db -d '"another_replicator_db"'
"_replicator"</pre><p>
        As soon as this is done, both pull replications defined before,
        are stopped. This is explicitly mentioned in CouchDB's log:
      </p><pre class="programlisting">[Fri, 11 Mar 2011 07:44:20 GMT] [info] [&lt;0.104.0&gt;] Stopping all ongoing replications because the replicator database was deleted or changed
[Fri, 11 Mar 2011 07:44:20 GMT] [info] [&lt;0.127.0&gt;] 127.0.0.1 - - PUT /_config/replicator/db 200</pre><p>
        Imagine now you add a replication document to the new replicator
        database named <code class="literal">another_replicator_db</code>:
      </p><pre class="programlisting">{
    "_id": "rep_from_X",
    "source":  "http://xserver.com:5984/foo",
    "target":  "foo_x",
    "continuous":  true
}</pre><p>
        From now own you have a single replication going on in your
        system: a pull replication pulling from server X. Now you change
        back the replicator database to the original one
        <code class="literal">_replicator</code>:
      </p><pre class="programlisting">$ curl -X PUT http://localhost:5984/_config/replicator/db -d '"_replicator"'
"another_replicator_db"</pre><p>
        Immediately after this operation, the replication pulling from
        server X will be stopped and the replications defined in the
        _replicator database (pulling from servers A and B) will be
        resumed.
      </p><p>
        Changing again the replicator database to
        <code class="literal">another_replicator_db</code> will stop the pull
        replications pulling from servers A and B, and resume the pull
        replication pulling from server X.
      </p></div><div class="section" title="2.6.&nbsp;Replicating the replicator database"><div class="titlepage"><div><div><h3 class="title"><a name="couchdb-release-1.1-replicatordb-replicating"></a>2.6.&nbsp;Replicating the replicator database</h3></div></div></div><p>
        Imagine you have in server C a replicator database with the two
        following pull replication documents in it:
      </p><pre class="programlisting">{
     "_id": "rep_from_A",
     "source":  "http://aserver.com:5984/foo",
     "target":  "foo_a",
     "continuous":  true,
     "_replication_id":  "c0ebe9256695ff083347cbf95f93e280",
     "_replication_state":  "triggered",
     "_replication_state_time":  1297971311
}
{
     "_id": "rep_from_B",
     "source":  "http://bserver.com:5984/foo",
     "target":  "foo_b",
     "continuous":  true,
     "_replication_id":  "231bb3cf9d48314eaa8d48a9170570d1",
     "_replication_state":  "triggered",
     "_replication_state_time":  1297974122
}</pre><p>
        Now you would like to have the same pull replications going on
        in server D, that is, you would like to have server D pull
        replicating from servers A and B. You have two options:
      </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>
            Explicitly add two documents to server's D replicator
            database
          </p></li><li class="listitem"><p>
            Replicate server's C replicator database into server's D
            replicator database
          </p></li></ul></div><p>
        Both alternatives accomplish exactly the same goal.
      </p></div><div class="section" title="2.7.&nbsp;Delegations"><div class="titlepage"><div><div><h3 class="title"><a name="couchdb-release-1.1-replicatordb-delegations"></a>2.7.&nbsp;Delegations</h3></div></div></div><p>
        Replication documents can have a custom
        <code class="literal">user_ctx</code> property. This property defines the
        user context under which a replication runs. For the old way of
        triggering replications (POSTing to
        <code class="literal">/_replicate/</code>), this property was not needed
        (it didn't exist in fact) - this is because at the moment of
        triggering the replication it has information about the
        authenticated user. With the replicator database, since it's a
        regular database, the information about the authenticated user
        is only present at the moment the replication document is
        written to the database - the replicator database implementation
        is like a _changes feed consumer (with
        <code class="literal">?include_docs=true</code>) that reacts to what was
        written to the replicator database - in fact this feature could
        be implemented with an external script/program. This
        implementation detail implies that for non admin users, a
        <code class="literal">user_ctx</code> property, containing the user's name
        and a subset of his/her roles, must be defined in the
        replication document. This is ensured by the document update
        validation function present in the default design document of
        the replicator database. This validation function also ensure
        that a non admin user can set a user name property in the
        <code class="literal">user_ctx</code> property that doesn't match his/her
        own name (same principle applies for the roles).
      </p><p>
        For admins, the <code class="literal">user_ctx</code> property is
        optional, and if it's missing it defaults to a user context with
        name null and an empty list of roles - this mean design
        documents will not be written to local targets. If writing
        design documents to local targets is desired, the a user context
        with the roles <code class="literal">_admin</code> must be set explicitly.
      </p><p>
        Also, for admins the <code class="literal">user_ctx</code> property can be
        used to trigger a replication on behalf of another user. This is
        the user context that will be passed to local target database
        document validation functions.
      </p><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
          The <code class="literal">user_ctx</code> property only has effect for
          local endpoints.
        </p></div><p>
        Example delegated replication document:
      </p><pre class="programlisting">{
     "_id": "my_rep",
     "source":  "http://bserver.com:5984/foo",
     "target":  "bar",
     "continuous":  true,
     "user_ctx": {
          "name": "joe",
          "roles": ["erlanger", "researcher"]
     }
}</pre><p>
        As stated before, for admins the user_ctx property is optional,
        while for regular (non admin) users it's mandatory. When the
        roles property of <code class="literal">user_ctx</code> is missing, it
        defaults to the empty list <code class="literal">[ ]</code>.
      </p></div></div><div class="section" title="3.&nbsp;Native SSL Support"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="couchdb-release-1.1-ssl"></a>3.&nbsp;Native SSL Support</h2></div></div></div><p>
      CouchDB 1.1 supports SSL natively. All your secure connection
      needs can now be served without the need set and maintain a
      separate proxy server that handles SSL.
    </p><p>
      SSL setup can be tricky, but the configuration in CouchDB was
      designed to be as easy as possible. All you need is two files; a
      certificate and a private key. If you bought an official SSL
      certificate from a certificate authority, both should be in your
      possession already.
    </p><p>
      If you just want to try this out and don't want to pay anything
      upfront, you can create a self-signed certificate. Everything will
      work the same, but clients will get a warning about an insecure
      certificate.
    </p><p>
      You will need the OpenSSL command line tool installed. It probably
      already is.
    </p><pre class="programlisting">shell&gt; <strong class="userinput"><code>mkdir cert &amp;&amp; cd cert</code></strong>
shell&gt; <strong class="userinput"><code>openssl genrsa &gt; privkey.pem</code></strong>
shell&gt; <strong class="userinput"><code>openssl req -new -x509 -key privkey.pem -out mycert.pem -days 1095</code></strong>
shell&gt; <strong class="userinput"><code>ls</code></strong>
mycert.pem privkey.pem</pre><p>
      Now, you need to edit CouchDB's configuration, either by editing
      your <code class="filename">local.ini</code> file or using the
      <code class="literal">/_config</code> API calls or the configuration screen
      in Futon. Here is what you need to do in
      <code class="filename">local.ini</code>, you can infer what needs doing in
      the other places.
    </p><p>
      Be sure to make these edits. Under <code class="literal">[daemons]</code>
      you should see:
    </p><pre class="programlisting">; enable SSL support by uncommenting the following line and supply the PEM's below.
; the default ssl port CouchDB listens on is 6984
;httpsd = {couch_httpd, start_link, [https]}</pre><p>
      Here uncomment the last line:
    </p><pre class="programlisting">httpsd = {couch_httpd, start_link, [https]}</pre><p>
      Next, under <code class="literal">[ssl]</code> you will see:
    </p><pre class="programlisting">;cert_file = /full/path/to/server_cert.pem
;key_file = /full/path/to/server_key.pem</pre><p>
      Uncomment and adjust the paths so it matches your system's paths:
    </p><pre class="programlisting">cert_file = /home/jan/cert/mycert.pem
key_file = /home/jan/cert/privkey.pem</pre><p>
      For more information please read
      <a class="ulink" href="http://www.openssl.org/docs/HOWTO/certificates.txt" target="_top">http://www.openssl.org/docs/HOWTO/certificates.txt</a>.
    </p><p>
      Now start (or restart) CouchDB. You should be able to connect to
      it using HTTPS on port 6984:
    </p><pre class="programlisting">shell&gt; <strong class="userinput"><code>curl https://127.0.0.1:6984/</code></strong>
curl: (60) SSL certificate problem, verify that the CA cert is OK. Details:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed
More details here: http://curl.haxx.se/docs/sslcerts.html

curl performs SSL certificate verification by default, using a "bundle"
of Certificate Authority (CA) public keys (CA certs). If the default
bundle file isn't adequate, you can specify an alternate file
using the --cacert option.
If this HTTPS server uses a certificate signed by a CA represented in
the bundle, the certificate verification probably failed due to a
problem with the certificate (it might be expired, or the name might
not match the domain name in the URL).
If you'd like to turn off curl's verification of the certificate, use
the -k (or --insecure) option.</pre><p>
      Oh no what happened?! &mdash; Remember, clients will notify their
      users that your certificate is self signed.
      <span class="command"><strong>curl</strong></span> is the client in this case and it notifies
      you. Luckily you trust yourself (don't you?) and you can specify
      the <code class="option">-k</code> option as the message reads:
    </p><pre class="programlisting">shell&gt; <strong class="userinput"><code>curl -k https://127.0.0.1:6984/</code></strong>
{"couchdb":"Welcome","version":"1.1.0"}</pre><p>
      All done.
    </p></div><div class="section" title="4.&nbsp;HTTP Range Requests"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="couchdb-release-1.1-httprange"></a>4.&nbsp;HTTP Range Requests</h2></div></div></div><p>
      HTTP allows you to specify byte ranges for requests. This allows
      the implementation of resumable downloads and skippable audio and
      video streams alike. Now this is available for all attachments
      inside CouchDB.
    </p><p>
      This is just a real quick run through how this looks under the
      hood. Usually, you will have larger binary files to serve from
      CouchDB, like MP3s and videos, but to make things a little more
      obvious, I use a text file here (Note that I use the
      <code class="literal">application/octet-stream</code> Content-Type instead
      of <code class="literal">text/plain</code>).
    </p><pre class="programlisting">shell&gt; <strong class="userinput"><code>cat file.txt </code></strong>
My hovercraft is full of eels!</pre><p>
      Now lets store this text file as an attachment in CouchDB. First,
      we create a database:
    </p><pre class="programlisting">shell&gt; <strong class="userinput"><code>curl -X PUT http://127.0.0.1:5984/test</code></strong>
{"ok":true}</pre><p>
      Then we create a new document and the file attachment in one go:
    </p><pre class="programlisting">shell&gt; <strong class="userinput"><code>curl -X PUT http://127.0.0.1:5984/test/doc/file.txt -H "Content-Type: application/octet-stream" -d@file.txt</code></strong>
{"ok":true,"id":"doc","rev":"1-287a28fa680ae0c7fb4729bf0c6e0cf2"}</pre><p>
      Now we can request the whole file easily:
    </p><pre class="programlisting">shell&gt; <strong class="userinput"><code>curl -X GET http://127.0.0.1:5984/test/doc/file.txt</code></strong>
My hovercraft is full of eels!</pre><p>
      But say we only want the first 13 bytes:
    </p><pre class="programlisting">shell&gt; <strong class="userinput"><code>curl -X GET http://127.0.0.1:5984/test/doc/file.txt -H "Range: bytes=0-12"</code></strong>
My hovercraft</pre><p>
      HTTP supports many ways to specify single and even multiple byte
      rangers. Read all about it in
      <a class="ulink" href="http://tools.ietf.org/html/rfc2616#section-14.27" target="_top">RFC
      2616</a>.
    </p><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
        Databases that have been created with CouchDB 1.0.2 or earlier
        will support range requests in 1.1.0, but they are using a
        less-optimal algorithm. If you plan to make heavy use of this
        feature, make sure to compact your database with CouchDB 1.1.0
        to take advantage of a better algorithm to find byte ranges.
      </p></div></div><div class="section" title="5.&nbsp;HTTP Proxying"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="couchdb-release-1.1-proxying"></a>5.&nbsp;HTTP Proxying</h2></div></div></div><p>
      The HTTP proxy feature makes it easy to map and redirect different
      content through your CouchDB URL. The proxy works by mapping a
      pathname and passing all content after that prefix through to the
      configured proxy address.
    </p><p>
      Configuration of the proxy redirect is handled through the
      <code class="literal">[httpd_global_handlers]</code> section of the CouchDB
      configuration file (typically <code class="filename">local.ini</code>). The
      format is:
    </p><pre class="programlisting">[httpd_global_handlers]
PREFIX = {couch_httpd_proxy, handle_proxy_req, &lt;&lt;"DESTINATION"&gt;&gt;}</pre><p>
      Where:
    </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>
          <code class="literal">PREFIX</code>
        </p><p>
          Is the string that will be matched. The string can be any
          valid qualifier, although to ensure that existing database
          names are not overridden by a proxy configuration, you can use
          an underscore prefix.
        </p></li><li class="listitem"><p>
          <code class="literal">DESTINATION</code>
        </p><p>
          The fully-qualified URL to which the request should be sent.
          The destination must include the <code class="literal">http</code>
          prefix. The content is used verbatim in the original request,
          so you can also forward to servers on different ports and to
          specific paths on the target host.
        </p></li></ul></div><p>
      The proxy process then translates requests of the form:
    </p><pre class="programlisting">http://couchdb:5984/PREFIX/path</pre><p>
      To:
    </p><pre class="programlisting">DESTINATION/path</pre><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
        Everything after <code class="literal">PREFIX</code> including the
        required forward slash will be appended to the
        <code class="literal">DESTINATION</code>.
      </p></div><p>
      The response is then communicated back to the original client.
    </p><p>
      For example, the following configuration:
    </p><pre class="programlisting">_google = {couch_httpd_proxy, handle_proxy_req, &lt;&lt;"http://www.google.com"&gt;&gt;}</pre><p>
      Would forward all requests for
      <code class="literal">http://couchdb:5984/_google</code> to the Google
      website.
    </p><p>
      The service can also be used to forward to related CouchDB
      services, such as Lucene:
    </p><pre class="programlisting">[httpd_global_handlers]
_fti = {couch_httpd_proxy, handle_proxy_req, &lt;&lt;"http://127.0.0.1:5985"&gt;&gt;}</pre><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
        The proxy service is basic. If the request is not identified by
        the <code class="literal">DESTINATION</code>, or the remainder of the
        <code class="literal">PATH</code> specification is incomplete, the
        original request URL is interpreted as if the
        <code class="literal">PREFIX</code> component of that URL does not exist.
      </p><p>
        For example, requesting
        <code class="literal">http://couchdb:5984/_intranet/media</code> when
        <code class="filename">/media</code> on the proxy destination does not
        exist, will cause the request URL to be interpreted as
        <code class="literal">http://couchdb:5984/media</code>. Care should be
        taken to ensure that both requested URLs and destination URLs
        are able to cope
      </p></div></div><div class="section" title="6.&nbsp;Added CommonJS support to map functions"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="couchdb-release-1.1-commonjs"></a>6.&nbsp;Added CommonJS support to map functions</h2></div></div></div><p>
      We didn't have CommonJS require in map functions because the
      current CommonJS implementation is scoped to the whole design doc,
      and giving views access to load code from anywhere in the design
      doc would mean we'd have to blow away your view index any time you
      changed anything. Having to rebuild views from scratch just
      because you changed some CSS or a show function isn't fun, so we
      avoided the issue by keeping CommonJS require out of map and
      reduce altogether.
    </p><p>
      The solution we came up with is to allow CommonJS inside map and
      reduce funs, but only of libraries that are stored inside the
      views part of the design doc.
    </p><p>
      So you could continue to access CommonJS code in design_doc.foo,
      from your list functions etc, but we'd add the ability to require
      CommonJS modules within map and reduce, but only from
      design_doc.views.lib
    </p><p>
      There's no worry here about namespace collisions, as Couch just
      plucks <code class="literal">views.*.map</code> and
      <code class="literal">views.*.reduce</code> out of the design doc. So you
      could have a view called <code class="literal">lib</code> if you wanted, and
      still have CommonJS stored in <code class="literal">views.lib.sha1</code>
      and <code class="literal">views.lib.stemmer</code> if you wanted.
    </p><p>
      We simplified the implementation by enforcing that CommonJS
      modules to be used in map functions be stored in views.lib.
    </p><p>
      A sample design doc (taken from the test suite in Futon) is below:
    </p><pre class="programlisting">{
   "views" : {
      "lib" : {
         "baz" : "exports.baz = 'bam';",
         "foo" : {
            "zoom" : "exports.zoom = 'yeah';",
            "boom" : "exports.boom = 'ok';",
            "foo" : "exports.foo = 'bar';"
         }
      },
      "commonjs" : {
         "map" : "function(doc) { emit(null, require('views/lib/foo/boom').boom)}"
      }
   },
   "_id" : "_design/test"
}</pre><p>
      The <code class="literal">require()</code> statement is relative to the
      design document, but anything loaded form outside of
      <code class="literal">views/lib</code> will fail.
    </p></div><div class="section" title="7.&nbsp;More granular ETag support for views"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="couchdb-release-1.1-etag"></a>7.&nbsp;More granular ETag support for views</h2></div></div></div><p>
      ETags have been assigned to a map/reduce group (the collection of
      views in a single design document). Any change to any of the
      indexes for those views would generate a new ETag for all view
      URL's in a single design doc, even if that specific view's results
      had not changed.
    </p><p>
      In CouchDB 1.1 each <code class="literal">_view</code> URL has it's own ETag
      which only gets updated when changes are made to the database that
      effect that index. If the index for that specific view does not
      change, that view keeps the original ETag head (therefore sending
      back 304 Not Modified more often).
    </p></div><div class="section" title="8.&nbsp;Added built-in filters for _changes: _doc_ids and _design."><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="couchdb-release-1.1-filters"></a>8.&nbsp;Added built-in filters for <code class="literal">_changes</code>:
      <code class="literal">_doc_ids</code> and <code class="literal">_design</code>.</h2></div></div></div><p>
      The <code class="literal">_changes</code> feed can now be used to watch
      changes to specific document ID's or the list of
      <code class="literal">_design</code> documents in a database. If the
      <code class="literal">filters</code> parameter is set to
      <code class="literal">_doc_ids</code> a list of doc IDs can be passed in the
      "doc_ids" as a JSON array.
    </p></div><div class="section" title="9.&nbsp;Allow wildcards in vhosts definitions"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="couchdb-release-1.1-wildcards"></a>9.&nbsp;Allow wildcards in vhosts definitions</h2></div></div></div><p>
      Similar to the rewrites section of a <code class="literal">_design</code>
      document, the new <code class="literal">vhosts</code> system uses variables
      in the form of :varname or wildcards in the form of asterisks. The
      variable results can be output into the resulting path as they are
      in the rewriter.
    </p></div><div class="section" title="10.&nbsp;OS Daemons"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="couchdb-release-1.1-osprocess"></a>10.&nbsp;OS Daemons</h2></div></div></div><p>
      CouchDB now supports starting external processes. The support is
      simple and enables CouchDB to start each configured OS daemon. If
      the daemon stops at any point, CouchDB will restart it (with
      protection to ensure regularly failing daemons are not repeatedly
      restarted).
    </p><p>
      The daemon starting process is one-to-one; for each each
      configured daemon in the configuration file, CouchDB will start
      exactly one instance. If you need to run multiple instances, then
      you must create separate individual configurations. Daemons are
      configured within the <code class="literal">[os_daemons]</code> section of
      your configuration file (<code class="filename">local.ini</code>). The
      format of each configured daemon is:
    </p><pre class="programlisting">NAME = PATH ARGS</pre><p>
      Where <code class="literal">NAME</code> is an arbitrary (and unique) name to
      identify the daemon; <code class="literal">PATH</code> is the full path to
      the daemon to be executed; <code class="literal">ARGS</code> are any
      required arguments to the daemon.
    </p><p>
      For example:
    </p><pre class="programlisting">[os_daemons]
basic_responder = /usr/local/bin/responsder.js</pre><p>
      There is no interactivity between CouchDB and the running process,
      but you can use the OS Daemons service to create new HTTP servers
      and responders and then use the new proxy service to redirect
      requests and output to the CouchDB managed service. For more
      information on proxying, see
      <a class="xref" href="#couchdb-release-1.1-proxying" title="5.&nbsp;HTTP Proxying">Section&nbsp;5, &ldquo;HTTP Proxying&rdquo;</a>. For further
      background on the OS Daemon service, see
      <a class="ulink" href="http://davispj.com/2010/09/26/new-couchdb-externals-api.html" target="_top">CouchDB
      Externals API</a>
    </p></div><div class="section" title="11.&nbsp;Stale views and update_after"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="coudhdb-release-1.1-updateafter"></a>11.&nbsp;Stale views and <code class="literal">update_after</code></h2></div></div></div><p>
      Currently a view request can include the
      <code class="literal">stale=ok</code> query argument, which allows the
      contents of a stale view index to be used to produce the view
      output. In order to trigger a build of the outdated view index, a
      second view request must be made.
    </p><p>
      To simplify this process, the <code class="literal">update_after</code>
      value can be supplied to the <code class="literal">stale</code> query
      argument. This triggers a rebuild of the view index after the
      results of the view have been retrieved.
    </p></div><div class="section" title="12.&nbsp;Socket Options Configuration Setting"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="couchdb-release-1.1-socketoptions"></a>12.&nbsp;Socket Options Configuration Setting</h2></div></div></div><p>
      The socket options for the listening socket in CouchDB can now be
      set within the CouchDB configuration file. The setting should be
      added to the <code class="literal">[httpd]</code> section of the file using
      the option name <code class="literal">socket_options</code>. The
      specification is as a list of tuples. For example:
    </p><pre class="programlisting">[httpd]
socket_options = [{recbuf, 262144}, {sndbuf, 262144}, {nodelay, true}]</pre><p>
      The options supported are a subset of full options supported by
      the TCP/IP stack. A list of the supported options are provided in
      the
      <a class="ulink" href="http://www.erlang.org/doc/man/inet.html#setopts-2" target="_top">Erlang
      inet</a> documentation.
    </p></div><div class="section" title="13.&nbsp;Server Options Configuration Setting"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="couchdb-release-1.1-serveroptions"></a>13.&nbsp;Server Options Configuration Setting</h2></div></div></div><p>
      Server options for the MochiWeb component of CouchDB can now be
      added to the configuration file. Settings should be added to the
      <code class="literal">server_options</code> option of the
      <code class="literal">[httpd]</code> section of
      <code class="filename">local.ini</code>. For example:
    </p><pre class="programlisting">[httpd]
server_options = [{backlog, 128}, {acceptor_pool_size, 16}]</pre></div><div class="section" title="14.&nbsp;Improved Error Messages"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="couchdb-release-1.1-errormessages"></a>14.&nbsp;Improved Error Messages</h2></div></div></div><p>
      The errors reported when CouchDB is unable to read a required file
      have been updated so that explicit information about the files and
      problem can now be identified from the error message. The errors
      report file permission access either when reading or writing to
      configuration and database files.
    </p><p>
      The error is raised both through the log file and the error
      message returned through the API call as a JSON error message. For
      example, when setting configuration values:
    </p><pre class="programlisting">shell&gt; <strong class="userinput"><code>curl -H 'X-Couch-Persist: true' -X PUT http://couchdb:5984/_config/couchdb/delayed_commits -d '"false"'</code></strong>
{"error":"file_permission_error","reason":"/etc/couchdb/local.ini"}</pre><p>
      Errors will always be reported using the
      <code class="literal">file_permission_error</code> error type.
    </p><p>
      During startup permissions errors on key files are also reported
      in the log with a descriptive error message and file location so
      that permissions can be fixed before restart.
    </p></div><div class="section" title="15.&nbsp;Multiple micro-optimizations when reading data."><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="couchdb-release-1.1-microoptimizations"></a>15.&nbsp;Multiple micro-optimizations when reading data.</h2></div></div></div><p>
      We found a number of places where CouchDB wouldn't do the absolute
      optimal thing when reading data and got rid of quite a few
      inefficiencies. The problem with small optimizations all over the
      place is that you may not notice them with every use-case, but we
      sure hope you can see an improvement overall.
    </p></div></div></body></html>